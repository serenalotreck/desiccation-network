{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WoS dataset filtering\n",
    "In this notebok, we'll address the problem of filtering out irrelevant papers from our Web of Science-generated dataset. We'll explore a few approaches to this problem, including filtering based on static and dynamic WoS keywords. We'll then evaluate our approaches on a subset of abstracts annotated for whether or not theyshould be kept or removed from the dataset (relevance labeled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data\n",
    "\n",
    "In the `WoS_dataset_characterization.ipynb` notebook, I played around with using word embedding clustering to determine which keywords were relevant/irrelevant for our task. I found that while the clustering does an impressive job of grouping keywords semantically, the semantic axis on which they cluster tends to be things like scientific disciplines, chemical and protein names, all of which contain both relevant and irrelevant terms for our subject matter. Therefore, I decided to move ahead by manually labelling the keywords as relevant or not. Because the keywords are viewed in isolation of their context (i.e. without looking at the abstract that they describe), and because it's very possible that multiple papers with the same keyword are both relevant and irrelevant, it's not a guarantee that this method is any better, so we want to evaluate the method against a test set of manually labeled abstracts. We'll read in all three sets of labels here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UPDATE with newest version when available\n",
    "with jsonlines.open('../data/wos_files/core_collection_destol_or_anhydro_ALL_03Jan2024_sequential.jsonl') as reader:\n",
    "    data = []\n",
    "    for obj in reader:\n",
    "        data.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamos_ann1 = pd.read_csv('../data/wos_files/dynamic_keys_relevance_classified_27Dec2023.csv', index_col=0)\n",
    "dynamos_ann2 = pd.read_csv('../data/wos_files/dynamic_keys_labeled_Ian_04Jan2024.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "statics_ann1 = pd.read_csv('../data/wos_files/static_keys_relevance_classified_27Dec2023.csv', index_col=0)\n",
    "statics_ann2 = pd.read_csv('../data/wos_files/static_keys_labeled_Ian_04Jan2024.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO read in both annotations of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating IAA\n",
    "We'll use [Cohen's kappa](https://surge-ai.medium.com/inter-annotator-agreement-an-introduction-to-cohens-kappa-statistic-dcc15ffa5ac4) for calculating this metric, which is defined as:\n",
    "\n",
    "$$\\frac{P_{o} - P_{e}}{1 - P_{e}}$$\n",
    "\n",
    "Where $P_{o}$ is the numebr of times both raters assigned the same label, and $P_{e}$ is the probability that btoh raters would choose the same label if they guessed randomly. We'll code up a function to calculate these values to get the overall Cohen's kappa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_kappa(ann1, ann2):\n",
    "    \"\"\"\n",
    "    Compute the cohen's kappa for a set of annotations.\n",
    "    \n",
    "    parameters:\n",
    "        ann1, df: annotator1's annotations\n",
    "        ann2, df: annotator2's annotations\n",
    "    \n",
    "    returns:\n",
    "        kappa, float: cohen's kappa\n",
    "    \"\"\"\n",
    "    # Merge the two dfs\n",
    "    anns = ann1.merge(ann2, left_index=True, right_index=True, suffixes=('_ann1', '_ann2'))\n",
    "    \n",
    "    # Calculate the input values\n",
    "    total = len(anns)\n",
    "    tp = len(anns[(anns['relevant_ann1'] == anns['relevant_ann2']) & (anns['relevant_ann1'] == 'Y')])\n",
    "    tn = len(anns[(anns['relevant_ann1'] == anns['relevant_ann2']) & (anns['relevant_ann1'] == 'N')])\n",
    "    fp = len(anns[(anns['relevant_ann1'] != anns['relevant_ann2']) & (anns['relevant_ann1'] == 'Y')])\n",
    "    fn = len(anns[(anns['relevant_ann1'] != anns['relevant_ann2']) & (anns['relevant_ann1'] == 'N')])\n",
    "    Po = (tp + tn)/total\n",
    "    P1 = ((tp + fn)*(tp + fp))/total**2\n",
    "    P2 = ((tn + fn) * (tn + fp))/total**2\n",
    "    Pe = P1 + P2\n",
    "    \n",
    "    # Calculate the overall value\n",
    "    kappa = (Po - Pe)/(1 - Pe)\n",
    "    \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### IAA on keywords\n",
    "First, we want to calculate an IAA for our labels of the keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement on the dynamic keywords was 0.10\n"
     ]
    }
   ],
   "source": [
    "dynamo_iaa = cohens_kappa(dynamos_ann1, dynamos_ann2)\n",
    "print(f'Agreement on the dynamic keywords was {dynamo_iaa:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement on the static keywords was 0.38\n"
     ]
    }
   ],
   "source": [
    "static_iaa = cohens_kappa(statics_ann1, statics_ann2)\n",
    "print(f'Agreement on the static keywords was {static_iaa:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These agreements are terrible! However, with the keywords, it's important to consider the fact that, since they're completely out of context (on purpose), this is an extremely opinionated task. Potentially, one person's opinion is more correct than another's as evaluated on the test set; so for now I'm going to keep the keyword annotaions separate and treat them as separate filtering \"methods\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAA on test set\n",
    "We will also calculate the IAA for the test set -- it's more important that this be relatively high, as we want consensus, it should be less of an outright opinion task and more self-evident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing filtering methods\n",
    "There are multiple of both static and dynamic keywords for most papers. Therefore, there are a few ways that we can choose to filter papers based on the classified keywords. We'll implement the following:\n",
    "\n",
    "1. Most stringent: To keep a paper, all keywords must have Y relevance\n",
    "2. Middle road: To keep a paper, the majority of keywords have Y relevance\n",
    "3. Least stringent: To keep a paper, only one keyword needs a Y relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_papers(papers, key_df, kind, stringency='most'):\n",
    "    \"\"\"\n",
    "    Filter papers by keyword.\n",
    "    \n",
    "    parameters:\n",
    "        papers, list of dict: papers to filter\n",
    "        key_df, pandas df: index are keywords, column is 'relevant' containing Y or N strings\n",
    "        kind, str: either 'static_keywords' or 'dynamic_keys' ## TODO change to static_keys for udpated dataset\n",
    "        stringency, str: 'most', 'middle', or 'least', default is 'most'\n",
    "    \n",
    "    returns:\n",
    "        filtered_papers, list of dict: list of papers with irrelevant papers removed\n",
    "    \"\"\"\n",
    "    filtered_papers = []\n",
    "    for paper in papers:\n",
    "        # Get the relevances of all keywords\n",
    "        keys = paper[kind]\n",
    "        key_rels = key_df.loc[keys, :]\n",
    "        # Filter based on requested stringency\n",
    "        if stringency == 'most':\n",
    "            if (len(key_rels['relevant'].unique()) == 1) and (key_rels['relevant'].unique()[0] == 'Y'):\n",
    "                filtered_papers.append(paper)\n",
    "        elif stringency == 'middle':\n",
    "            nums = Counter(key_rels['relevant'].values.tolist())\n",
    "            if nums['Y'] > nums['N']:\n",
    "                filtered_papers.append(paper)\n",
    "        elif stringency == 'least':\n",
    "            if 'Y' in key_rels.relevant.values.tolist():\n",
    "                filtered_papers.append(papers)\n",
    "    \n",
    "    print(f'{len(filtered_papers)} of {len(papers)} were kept upon filtering.')\n",
    "    return filtered_papers        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing filtering methods\n",
    "TODO: Actually test on test set\n",
    "\n",
    "Now, let's see how each of these filtering methods impacts the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic keywords\n",
    "#### Most stringent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4044 of 6903 were kept upon filtering.\n"
     ]
    }
   ],
   "source": [
    "most_dynamo = filter_papers(data, dynamos, 'dynamic_keys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Middle road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5796 of 6903 were kept upon filtering.\n"
     ]
    }
   ],
   "source": [
    "middle_dynamo = filter_papers(data, dynamos, 'dynamic_keys', stringency='middle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least stringent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6380 of 6903 were kept upon filtering.\n"
     ]
    }
   ],
   "source": [
    "least_dynamo = filter_papers(data, dynamos, 'dynamic_keys', stringency='least')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static keywords\n",
    "#### Most stringent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3978 of 6903 were kept upon filtering.\n"
     ]
    }
   ],
   "source": [
    "most_static = filter_papers(data, statics, 'static_keywords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Middle road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4692 of 6903 were kept upon filtering.\n"
     ]
    }
   ],
   "source": [
    "middle_static = filter_papers(data, statics, 'static_keywords', stringency='middle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least stringent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5963 of 6903 were kept upon filtering.\n"
     ]
    }
   ],
   "source": [
    "least_static = filter_papers(data, statics, 'static_keywords', stringency='least')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "graphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
