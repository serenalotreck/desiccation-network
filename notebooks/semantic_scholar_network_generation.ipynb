{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Semantic Scholar Network Generation\n",
    "In this notebook, we'll explore building a citation network on results of a specific search using the Semantic Scholar API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "import json\n",
    "import networkx as nx\n",
    "from statistics import mean, median\n",
    "from taxonerd import TaxoNERD\n",
    "import taxoniq\n",
    "import time\n",
    "from numpy import cumsum\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requesting Data\n",
    "This is an example of how to request data for a citation network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import API key. This must be requested from https://www.semanticscholar.org/product/api#api-key; we save ours in an untracked file in data and import here\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "from semantic_scholar_API_key import API_KEY\n",
    "header = {'x-api-key': API_KEY}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to look at the citations of papers that are returned when we search \"desiccation tolerance\" and \"anhydrobiosis\". We then want to use our previously written TaxoNERD code to get the study organisms and their kingdoms from the title ans abstracts. To do this, we need to build a query that will return some number of papers with title, abstract, and citations. A full reference of the properties we can request is found [here](https://api.semanticscholar.org/api-docs/#tag/Paper-Data/operation/get_graph_get_paper_search).\n",
    "\n",
    "Using the API, only 99 papers can be requested at a time (maximum value of the `limit` parameter). However, we want to get thousands of search results (the maximum depth we can request into the search results is 10,000). We can do this by combining the `limit` and `offset` parameters; the `offset` parameter tells the request how far down the search results to start retrieving our 99 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_results = []\n",
    "# for offset in tqdm(range(0, 10000, 100)):\n",
    "#     query = f'http://api.semanticscholar.org/graph/v1/paper/search?query=desiccation+tolerance&offset={offset}&limit=100&fields=title,abstract,references'\n",
    "#     search = requests.get(query, headers=header).json()\n",
    "#     search_results.append(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our results as a jsonlines so we can come back to it without having to request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with jsonlines.open('../data/semantic_scholar/desiccation-tolerance_10000_24Aug2023.jsonl', 'w') as writer:\n",
    "#     writer.write_all(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('../data/semantic_scholar/desiccation-tolerance_10000_24Aug2023.jsonl') as reader:\n",
    "    search_results = []\n",
    "    for obj in reader:\n",
    "        search_results.append(obj)\n",
    "# Flatten into one dict of just results\n",
    "search_results = [p for res in search_results for p in res['data']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We weren't able to get the abstracts for the citations when we originally pulled this information, so now let's get them secondarily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ref_dict = {}\n",
    "# for search_subset in tqdm(search_results):\n",
    "#     for paper in tqdm(search_subset['data']):\n",
    "#         for ref in paper['references']:\n",
    "#             query = f'http://api.semanticscholar.org/graph/v1/paper/{ref[\"paperId\"]}?fields=title,abstract'\n",
    "#             search = requests.get(query, headers=header).json()\n",
    "#             ref_dict[paper[\"paperId\"]] = search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell is prohibitively slow (~70h to get all reference abstracts). Let's explore how to make this quicker. Our first hypothesis is that a large number of references are likely overlapping, so we may be able to massively scale down the operation by ignoring anything that's already been read. Let's quantify that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = []\n",
    "for paper in search_results:\n",
    "    ref_ids = [ref['paperId'] for ref in paper['references']]\n",
    "    refs.extend(ref_ids)\n",
    "\n",
    "print(f'There are {len(refs)} total references, but only {len(set(refs))} are unique. This means we cut down our computation time on the order of {len(set(refs))/len(refs): .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey that's pretty good! however, that would stil be quite slow. I can also request multiple papers at once; would this make things more efficient? Let's use the `time` module to check. We want to get a sense of how the time scales with more instances included in a single request, compared to how long it would take to do each individually. We can make a plot to visualize this, using 20 references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_20 = list(set(refs))[:20]\n",
    "individual_times = {}\n",
    "for i, u in enumerate(unique_20):\n",
    "    query = f'http://api.semanticscholar.org/graph/v1/paper/{u}?fields=title,abstract'\n",
    "    start = time.time()\n",
    "    search = requests.get(query, headers=header).json()\n",
    "    individual_times[i] = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "together_times = {}\n",
    "for i in range(len(unique_20)):\n",
    "    start = time.time()\n",
    "    search = requests.post('https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "                          params={'fields': 'title,abstract'},\n",
    "                          json={'ids': unique_20[:i+1]}).json()\n",
    "    together_times[i] = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(individual_times.keys(), cumsum(list(individual_times.values())), label='individual')\n",
    "plt.plot(together_times.keys(), together_times.values(), label='together')\n",
    "plt.xlabel('Number of papers')\n",
    "plt.ylabel('Total time')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is an impressive speedup!! Woohoo! The limitation is that the post request can only take 500 paper ID's at a time, but that is still a substantial speedup from what I was doing before. After changing `pull_papers.py` to incorporate the post requests,the entire script, for all 10,000 search results, runs in about an hour. Let that serve as an example for why it's good to optimize things instead oif directly embarrasingly parallelizing them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in output from `pull_papers.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_path = '../data/semantic_scholar/desiccation-tolerance_10000_with_abstracts_for_refs_29Aug2023.json'\n",
    "with open(pull_path) as myf:\n",
    "    search_results = json.load(myf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building citation network\n",
    "We need to generate pairs of documents connected by citations. Conveniently, each paper has a unique ID generated by Semantic Scholar, which makes our lives somewhat easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the paper ID for a single search result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_results[0]['paperId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the paper ID's of its references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[p['paperId'] for p in search_results[0]['references']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Characterizing average number of citations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def characterize_citations(search_results):\n",
    "    \"\"\"\n",
    "    Get statistics about the number of citations per paper.\n",
    "    \n",
    "    parameters:\n",
    "        search_results, list of dict: query results\n",
    "    \"\"\"\n",
    "    num_cites = []\n",
    "    for paper in search_results:\n",
    "        num_cites.append(len(paper['references']))\n",
    "    print(f'Average number of citations per paper: {mean(num_cites): .2f}')\n",
    "    print(f'Median number of citations per paper: {median(num_cites)}')\n",
    "    print(f'Maximum number of citations per paper: {max(num_cites)}')\n",
    "    print(f'Minimum number of citations per paper: {min(num_cites)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "characterize_citations(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to generate links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_links(search_results):\n",
    "    \"\"\"\n",
    "    Generate a list of edges by paper ID from the results of a Semantic Scholar query.\n",
    "    \n",
    "    parameters:\n",
    "        search_results, list of dict: query results\n",
    "        \n",
    "    returns:\n",
    "        nodes, list of two-tuple: the paper ID and an attribute dictionary containing the paper's title\n",
    "        edges, list of three-tuple: the paper IDs of both citing and cited paper, and an attribute dictionary with the paper's title\n",
    "    \"\"\"\n",
    "    nodes, edges = [], []\n",
    "    for paper in search_results:\n",
    "        citing = (paper['paperId'], {'title': paper['title']})\n",
    "        cited = [(p['paperId'], {'title': p['title']}) for p in paper['references']]   \n",
    "        nodes.append(citing)\n",
    "        nodes.extend(cited)\n",
    "        edges.extend([(citing[0], p[0]) for p in cited])\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nodes, edges = generate_links(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some citations appear to have been improperly formatted somewhere along the line, and result in having no paper ID, and a title that's just part of a full citation (not the actual title of the paper being cited). How many nodes of the network does this comprise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'{(sum([1 for n in nodes if n[0] is None])/len(nodes))*100: .2f}% of the network\\'s nodes are malformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a relatively small percentage -- let's drop them for now, we can come back and troubleshoot later. We also now want to add the taxonomic classification as attributes to nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_orgs(ents, defs):\n",
    "    \"\"\"\n",
    "    Get organism classifications from a list of NCBI Taxonomy IDs\n",
    "\n",
    "    parameters:\n",
    "        ents, list of int: NCBI Taxonomy ID's\n",
    "        defs, dict: keys are lineage categories, values are the final\n",
    "            kingdom classification for those categories\n",
    "\n",
    "    returns:\n",
    "        kings, list of str: unique kingdom classifications\n",
    "    \"\"\"\n",
    "    kings = []\n",
    "    for i in ents:\n",
    "        try:\n",
    "            t1 = taxoniq.Taxon(i)\n",
    "            lineage = [t.scientific_name for t in t1.ranked_lineage]\n",
    "            if lineage[-1] == 'Bacteria' or lineage[-1] == 'Archea':\n",
    "                kings.append(defs[lineage[-1]])\n",
    "            elif lineage[-1] == 'Eukaryota':\n",
    "                try:\n",
    "                    kings.append(defs[lineage[-2]])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    kings = list(set(kings))\n",
    "    return kings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_title(title, abstract, taxonerd):\n",
    "    \"\"\"\n",
    "    Gets the Kingdom classification of a paper title.\n",
    "    \n",
    "    parameters:\n",
    "        title, str: title of the paper\n",
    "        abstract, str: abstract of the paper\n",
    "        taxonerd, TaxoNERD instance: model to use for classification\n",
    "\n",
    "    returns:\n",
    "        king, str: kindgom of the paper\n",
    "    \"\"\"\n",
    "    # Do TaxoNERD classification\n",
    "    title_df = taxonerd.find_in_text(title)\n",
    "    \n",
    "    # Get the unique organisms\n",
    "    title_ents = list(set([title_df['entity'][j][0][0].split(\"NCBI:\")[1] for j in\n",
    "            range(len(title_df))]))\n",
    "    \n",
    "    # Set up definitions for kingdom classification\n",
    "    defs = {\n",
    "            'Metazoa': 'Animal',\n",
    "            'Viridiplantae': 'Plant', # Consider adding algae\n",
    "            'Bacteria': 'Microbe',\n",
    "            'Archea': 'Microbe'\n",
    "            }\n",
    "    \n",
    "    # Classify unique organisms\n",
    "    title_classes = classify_orgs(title_ents, defs)\n",
    "    \n",
    "    # If abstract isn't None, also classify abstract\n",
    "    if abstract is not None:\n",
    "        abstract_df = taxonerd.find_in_text(abstract)\n",
    "        abstract_ents = list(set([abstract_df['entity'][j][0][0].split(\"NCBI:\")[1] for j in\n",
    "                range(len(abstract_df))]))\n",
    "        abstract_classes = classify_orgs(abstract_ents, defs)\n",
    "    else:\n",
    "        abstract_classes = []\n",
    "    \n",
    "    # Get the kingdom\n",
    "    if (len(title_classes) == len(abstract_classes) == 1) and (title_classes ==\n",
    "            abstract_classes):\n",
    "        king = title_classes[0]\n",
    "    elif len(title_classes) == 0 and len(abstract_classes) == 1:\n",
    "        king = abstract_classes[0]\n",
    "    elif len(abstract_classes) == 0 and len(title_classes) == 1:\n",
    "        king = title_classes[0]\n",
    "    else:\n",
    "        # For now, come back to this\n",
    "        king = 'NOCLASS'\n",
    "    return king\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_links_with_classification(search_results, taxonerd):\n",
    "    \"\"\"\n",
    "    Generate a list of edges by paper ID from the results of a Semantic Scholar query. Removes malformed\n",
    "    citations with no paperID, and classifies nodes by the organisms in their titles.\n",
    "    \n",
    "    parameters:\n",
    "        search_results, dict: query results\n",
    "        taxonerd, TaxoNERD instance: model to use for classification\n",
    "        \n",
    "    returns:\n",
    "        nodes, list of two-tuple: the paper ID and an attribute dictionary containing the paper's title\n",
    "        edges, list of three-tuple: the paper IDs of both citing and cited paper, and an attribute dictionary with the paper's title\n",
    "    \"\"\"\n",
    "    \n",
    "    # Classify nodes and identify edges\n",
    "    nodes, edges = [], []\n",
    "    i = 0\n",
    "    for paper in tqdm(search_results):\n",
    "        org = classify_title(paper['title'], paper['abstract'], taxonerd)\n",
    "        citing = (paper['paperId'], {'title': paper['title'], 'study_system': org})\n",
    "        cited = [(p['paperId'], {'title': p['title'], 'study_system': classify_title(p['title'], p['abstract'], taxonerd)}) for p in paper['references'] if p['paperId'] is not None]   \n",
    "        nodes.append(citing)\n",
    "        nodes.extend(cited)\n",
    "        edges.extend([(citing[0], p[0], num) for num, p in enumerate(cited, i)])\n",
    "        i += len(cited)\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define TaxoNERD model for classification\n",
    "taxonerd = TaxoNERD(prefer_gpu=False)\n",
    "nlp = taxonerd.load(model=\"en_core_eco_biobert\", linker=\"ncbi_taxonomy\", threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell is too memory intensive for my local machine, but there seem to be no bugs in the above code. Will transfer to a script and run as a job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nodes, edges = generate_links_with_classification(search_results, taxonerd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "citenet = nx.MultiDiGraph()\n",
    "_ = citenet.add_nodes_from(nodes)\n",
    "_ = citenet.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx.write_graphml(citenet, '../data/citation_network/network_des_10000_no_classification_25Aug2023.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "graphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
