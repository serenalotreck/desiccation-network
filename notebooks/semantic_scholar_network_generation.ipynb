{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8cf79c0-2f9b-45a3-8b11-d293b776cc44",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Semantic Scholar Network Generation\n",
    "In this notebook, we'll explore building a citation network on results of a specific search using the Semantic Scholar API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1e1a95c-64dc-4e33-ae15-e31533f6bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "import networkx as nx\n",
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f810211-8f7f-4a84-8d8f-6c259fc3f691",
   "metadata": {},
   "source": [
    "## Requesting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c850cc36-d6a7-4c72-abb8-e37a5a471651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import API key. This must be requested from https://www.semanticscholar.org/product/api#api-key; we save ours in an untracked file in data and import here\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "from semantic_scholar_API_key import API_KEY\n",
    "header = {'x-api-key': API_KEY}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956abf6d-7e8d-4203-bd3f-6fa5ac1e677d",
   "metadata": {},
   "source": [
    "We want to look at the citations of papers that are returned when we search \"desiccation tolerance\" and \"anhydrobiosis\". We then want to use our previously written TaxoNERD code to get the study organisms and their kingdoms from the title ans abstracts. To do this, we need to build a query that will return some number of papers with title, abstract, and citations. A full reference of the properties we can request is found [here](https://api.semanticscholar.org/api-docs/#tag/Paper-Data/operation/get_graph_get_paper_search).\n",
    "\n",
    "Using the API, only 99 papers can be requested at a time (maximum value of the `limit` parameter). However, we want to get thousands of search results (the maximum depth we can request into the search results is 10,000). We can do this by combining the `limit` and `offset` parameters; the `offset` parameter tells the request how far down the search results to start retrieving our 99 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd2af3cd-2269-4b28-9580-23d6d5536434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [09:00<00:00,  5.41s/it]\n"
     ]
    }
   ],
   "source": [
    "search_results = []\n",
    "for offset in tqdm(range(0, 10000, 100)):\n",
    "    query = f'http://api.semanticscholar.org/graph/v1/paper/search?query=desiccation+tolerance&offset={offset}&limit=99&fields=title,abstract,references'\n",
    "    search = requests.get(query, headers=header).json()\n",
    "    search_results.append(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4023d42f-7b48-42b8-8603-9981e4ef4633",
   "metadata": {},
   "source": [
    "Let's save our results as a jsonlines so we can come back to it without having to request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e00d2b60-b5e0-4600-8c14-d6efd7323019",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('../data/semantic_scholar/desiccation-tolerance_10000_24Aug2023.jsonl', 'w') as writer:\n",
    "    writer.write_all(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a46f52f-6063-4a08-92ca-47e0bc4704f9",
   "metadata": {},
   "source": [
    "Now we can experiment around and see if it's possible to build a citation network!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199eedc5-5257-43e5-9382-5af90d573cad",
   "metadata": {},
   "source": [
    "## Building citation network\n",
    "We need to generate pairs of documents connected by citations. Conveniently, each paper has a unique ID generated by Semantic Scholar, which makes our lives somewhat easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3acf4d-55ee-4234-aa0b-334ab35ccb0e",
   "metadata": {},
   "source": [
    "To get the paper ID for a single search result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a494db91-7689-4ead-b023-c1502c8860f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'393cc126bd647a8435072e788a2a033561c6fa97'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results[0]['data'][0]['paperId']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5cbe88-61c6-4772-a63c-edcb92b7b29d",
   "metadata": {},
   "source": [
    "To get the paper ID's of its references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15be48ea-b1ab-481d-90d9-5b15fdabff70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18d8e54e9f384361d3f6af634642e82d2479bef2',\n",
       " '2ee8adf45800831679c9ee226cf108b34197108b',\n",
       " 'af0eb5272536c8b1db53e671b77d9ea61e206ff5',\n",
       " '2b32eec751dbe123a7532cfac4fb3c8ce5295a37',\n",
       " '5f2084b6eb9286ee6930e2cc0d9e3c4f581def29',\n",
       " 'efcbec4baa59b1cbe9acada9bbc266b020b1560f',\n",
       " '8f8622842a9d31cb7fff1ff4433c28bfd10133df',\n",
       " '9405079823b201c061eec9b85f184702289f0472',\n",
       " 'c7937572a01f822d61d7f1b3eda5dfca10b06915',\n",
       " '12b1a3e2df680cd5a94ff89a356ef513f817cba9',\n",
       " '282bd0c59d247c35a1a0cbfd3708cd27bfcb9cbe',\n",
       " 'b812c9a1370d125b91af265dbd2f417b4329a9df',\n",
       " 'd79eedab7bae594f34c4d355510e57e2f21aecbe',\n",
       " 'a52b0768702008d78d474fc431b95b2a0288fc65']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p['paperId'] for p in search_results[0]['data'][0]['references']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a3707-1ac6-4f74-8e2c-ec79fc02a0d3",
   "metadata": {},
   "source": [
    "Characterizing average number of citations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "619f0789-527e-4cee-8bfb-b73c6f6fdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def characterize_citations(search_results):\n",
    "    \"\"\"\n",
    "    Get statistics about the number of citations per paper.\n",
    "    \n",
    "    parameters:\n",
    "        search_results, list of dict: query results\n",
    "    \"\"\"\n",
    "    num_cites = []\n",
    "    for result in search_results:\n",
    "        for paper in result['data']:\n",
    "            num_cites.append(len(paper['references']))\n",
    "    print(f'Average number of citations per paper: {mean(num_cites): .2f}')\n",
    "    print(f'Median number of citations per paper: {median(num_cites)}')\n",
    "    print(f'Maximum number of citations per paper: {max(num_cites)}')\n",
    "    print(f'Minimum number of citations per paper: {min(num_cites)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7cf43bf1-5cb0-4743-9692-2e7ad98090af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of citations per paper:  45.32\n",
      "Median number of citations per paper: 36.0\n",
      "Maximum number of citations per paper: 1000\n",
      "Minimum number of citations per paper: 0\n"
     ]
    }
   ],
   "source": [
    "characterize_citations(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e86bb-18f4-4600-994e-ed9d7f81cfe9",
   "metadata": {},
   "source": [
    "Define a function to generate links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4005d1c3-be0f-4462-83b3-48141b8553d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_links(search_results):\n",
    "    \"\"\"\n",
    "    Generate a list of edges by paper ID from the results of a Semantic Scholar query.\n",
    "    \n",
    "    parameters:\n",
    "        search_results, list of dict: query results\n",
    "        \n",
    "    returns:\n",
    "        nodes, list of two-tuple: the paper ID and an attribute dictionary containing the paper's title\n",
    "        edges, list of three-tuple: the paper IDs of both citing and cited paper, and an attribute dictionary with the paper's title\n",
    "    \"\"\"\n",
    "    nodes, edges = [], []\n",
    "    for result in search_results:\n",
    "        for paper in result['data']:\n",
    "            citing = (paper['paperId'], {'title': paper['title']})\n",
    "            cited = [(p['paperId'], {'title': p['title']}) for p in paper['references']]   \n",
    "            nodes.append(citing)\n",
    "            nodes.extend(cited)\n",
    "            edges.extend([(citing[0], p[0]) for p in cited])\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "908f107e-51f1-4822-b593-189ae2a01dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = generate_links(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df120d23-1dc4-40bd-88de-556c887e5524",
   "metadata": {},
   "source": [
    "Some citations appear to have been improperly formatted somewhere along the line, and result in having no paper ID, and a title that's just part of a full citation (not the actual title of the paper being cited). How many nodes of the network does this comprise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a63060c-7d5c-4d30-bfec-3bc08ecd1f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8.96% of the network's nodes are malformed\n"
     ]
    }
   ],
   "source": [
    "print(f'{(sum([1 for n in nodes if n[0] is None])/len(nodes))*100: .2f}% of the network\\'s nodes are malformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68bcc67-992b-4cae-be6c-a15ed84d1627",
   "metadata": {},
   "source": [
    "This is a relatively small percentage -- let's drop them for now, we can come back and troubleshoot later. We also now want to add the taxonomic classification as attributes to nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "087a87b5-c652-4bc2-988f-89909157dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_orgs(ents, defs):\n",
    "    \"\"\"\n",
    "    Get organism classifications from a list of NCBI Taxonomy IDs\n",
    "\n",
    "    parameters:\n",
    "        ents, list of int: NCBI Taxonomy ID's\n",
    "        defs, dict: keys are lineage categories, values are the final\n",
    "            kingdom classification for those categories\n",
    "\n",
    "    returns:\n",
    "        kings, list of str: unique kingdom classifications\n",
    "    \"\"\"\n",
    "    kings = []\n",
    "    for i in ents:\n",
    "        try:\n",
    "            t1 = taxoniq.Taxon(i)\n",
    "            lineage = [t.scientific_name for t in t1.ranked_lineage]\n",
    "            if lineage[-1] == 'Bacteria' or lineage[-1] == 'Archea':\n",
    "                kings.append(defs[lineage[-1]])\n",
    "            elif lineage[-1] == 'Eukaryota':\n",
    "                try:\n",
    "                    kings.append(defs[lineage[-2]])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    kings = list(set(kings))\n",
    "    return kings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "922ebd70-07d8-4661-a34f-942994fa2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_title(title):\n",
    "    \"\"\"\n",
    "    Gets the Kingdom classification of a paper title.\n",
    "    \n",
    "    parameters:\n",
    "        title, str: title of the paper\n",
    "    \n",
    "    returns:\n",
    "        king, str: kindgom of the paper\n",
    "    \"\"\"\n",
    "    # Do TaxoNERD classification\n",
    "    title_df = taxonerd.find_in_text(title)\n",
    "    \n",
    "    # Get the unique organisms\n",
    "    title_ents = list(set([title_df['entity'][j][0][0].split(\"NCBI:\")[1] for j in\n",
    "            range(len(title_df))]))\n",
    "    \n",
    "    # Set up definitions for kingdom classification\n",
    "    defs = {\n",
    "            'Metazoa': 'Animal',\n",
    "            'Viridiplantae': 'Plant', # Consider adding algae\n",
    "            'Bacteria': 'Microbe',\n",
    "            'Archea': 'Microbe'\n",
    "            }\n",
    "    \n",
    "    # Classify unique organisms\n",
    "    title_classes = classify_orgs(title_ents, defs)\n",
    "    \n",
    "    # Get the kingdom\n",
    "    king = title_classes[0]\n",
    "    \n",
    "    return king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f6de61e-ebfc-414f-adb9-54b18a66b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_links_with_classification(search_results):\n",
    "    \"\"\"\n",
    "    Generate a list of edges by paper ID from the results of a Semantic Scholar query. Removes malformed\n",
    "    citations with no paperID, and classifies nodes by the organisms in their titles.\n",
    "    \n",
    "    parameters:\n",
    "        search_results, list of dict: query results\n",
    "        \n",
    "    returns:\n",
    "        nodes, list of two-tuple: the paper ID and an attribute dictionary containing the paper's title\n",
    "        edges, list of three-tuple: the paper IDs of both citing and cited paper, and an attribute dictionary with the paper's title\n",
    "    \"\"\"\n",
    "    nodes, edges = [], []\n",
    "    for result in search_results:\n",
    "        for paper in result['data']:\n",
    "            citing = (paper['paperId'], {'title': paper['title']})\n",
    "            cited = [(p['paperId'], {'title': p['title'], }) for p in paper['references'] if p['paperId'] is not None]   \n",
    "            nodes.append(citing)\n",
    "            nodes.extend(cited)\n",
    "            edges.extend([(citing[0], p[0]) for p in cited])\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "188d1875-414e-48f1-89cb-5a3555d95a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = generate_links_no_empty(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34f9182e-c4a0-4c43-a230-8377c4def524",
   "metadata": {},
   "outputs": [],
   "source": [
    "citenet = nx.MultiDiGraph()\n",
    "_ = citenet.add_nodes_from(nodes)\n",
    "_ = citenet.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285ab323-7e6f-4230-81c5-6619e5f524f9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
